{"api":{"version":2,"latestVersion":2},"lesson":{"id":"chaines-markov","level":"terminale","title":"Chaînes de Markov","chapter":16,"specialty":true,"content":"/api/v2/terminale/chaines-markov/","comments":"/api/v2/terminale/chaines-markov/comments/","summary":"/api/v2/terminale/chaines-markov/summary/"},"html":"\n\n\n\n\n\n\n\n<h2 id=\"graphe-pondere-et-graphe-probabiliste\">Graphe pondéré et graphe probabiliste</h2>\n<h3 id=\"definition\">Définition</h3>\n<div class=\"formula\">\n<h4>Graphe pondéré</h4>\n<p>Un graphe est dit <strong>pondéré</strong> si chacune de ses arêtes\nest affecté d’un nombre positif (ou nul) que l’on appelle\n<strong>poids</strong>.</p>\n<p>Le poids d’une chaîne (ou d’un chemin) est la somme des poids de ses\narêtes.</p>\n</div>\n\n<div class=\"formula\">\n<h4>Graphe probabiliste</h4>\n<p>On appelle <strong>graphe probabiliste</strong> un graphe orienté et\npondéré tel que :</p>\n<ul>\n<li><p>Pour chaque sommet, la somme des poids des arcs issus de ce\nsommet vaut <math>1</math>.</p></li>\n<li><p>Il y a au plus <math>1</math> arrête orientée reliant\nchaque sommet.</p></li>\n</ul>\n</div>\n<p>Il peut être utile de faire l’analogie entre les graphes\nprobabilistes et <a href=\"https://bacomathiqu.es/cours/premiere/probabilites/#arbre-de-probabilite\">les\narbres de probabilité</a> vus en classe de Première.</p>\n\n<h3 id=\"matrice-de-transition\">Matrice de transition</h3>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit <math>G</math> un graphe probabiliste d’ordre <math>n</math>. On appelle <strong>matrice de transition</strong> du\ngraphe <math>G</math>, la matrice carrée d’ordre <math>n</math> dont le coefficient à la ligne <math>i</math>\net à la colonne <math>j</math> est égal au poids de l’arête\nreliant le sommet <math>i</math> au sommet <math>j</math>.</p>\n<p>Une telle matrice est qualifiée de <strong>stochastique</strong> car\nla somme des coefficients de chacune de ses lignes vaut <math>1</math>.</p>\n</div>\n\n<p>Attention cependant à ne pas confondre matrice de transition et\nmatrice d’adjacence.</p>\n<h2 id=\"chaines-de-markov\">Chaînes de Markov</h2>\n<h3 id=\"definition-1\">Définition</h3>\n<p>Il vous est fortement conseillé de relire (et de maîtriser) le cours\nsur <a href=\"https://bacomathiqu.es/cours/terminale/variables-aleatoires-concentration-grands-nombres/\">les\nvariables aléatoires</a> avant d’aborder cette section. De plus, sachez\nque cette partie est sans doute la plus difficile du programme de\nTerminale. Mais ne vous découragez pas car elle reste parfaitement\naccessible !</p>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit <math>(X_n)</math> une suite de variables aléatoires\ndiscrètes définies sur un même univers <math>\\Omega</math> et à\nvaleurs dans un ensemble <math>E</math>. On dit que <math>(X_n)</math> définit une <strong>chaîne de Markov</strong> sur\n<math>E</math> si pour tout <math>n \\in \\mathbb{N}</math>\net tout <math>x_0, x_1, x_2, \\dots, x_n \\in E</math>, l’événement\n<math>(X_n = x_n)</math> ne dépend que de l’événement antérieur\n<math>(X_{n-1} = x_{n-1})</math> (et pas des précédents) ;\nautrement dit, si <math>P_{(X_{n-1} = x_{n-1}) \\, \\cap \\dots \\cap \\, (X_0 = x_0)}(X_n = x_n) = P_{(X_{n-1} = x_{n-1})}(X_n = x_n)</math>.</p>\n<p>De plus, l’ensemble <math>E</math> est appelé <strong>espace\ndes états</strong> de la chaîne de Markov.</p>\n</div>\n<p>En français, cela signifie que si <math>X_n</math> représente\nl’état d’un système à un temps <math>n</math>, alors l’état\nsuivant <math>X_{n+1}</math> ne dépend que de l’état au temps <math>n</math> et pas des états précédents. De plus, notez bien que\nnous n’avons pas fait d’hypothèse sur le cardinal de <math>E</math> (qui peut donc être de cardinal <math>m \\in \\mathbb{N}</math>).</p>\n\n\n<div class=\"formula\">\n<h4>Chaîne de Markov homogène</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov dont on note <math>E</math> l’espace des états. Alors <math>(X_n)</math>\nest dite <strong>homogène</strong> si pour tout <math>n \\in \\mathbb{N}</math> et pour tout <math>x</math>, <math>y \\in E</math>, la probabilité <math>P_{(X_n = x)}(X_{n+1} = y)</math>\nest indépendante de <math>n</math>.</p>\n<p>En termes mathématiques, cela signifie que pour tout <math>n \\in \\mathbb{N}</math> et pour tout <math>x</math>, <math>y \\in E</math>, <math>P_{(X_n = x)}(X_{n+1} = y) = P_{(X_0 = x)}(X_1 = y)</math>.</p>\n</div>\n\n<h3 id=\"matrice-et-graphe-associes-a-une-chaine-de-markov\">Matrice et graphe associés à une chaîne de Markov</h3>\n<div class=\"formula\">\n<h4>Matrice de transition</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des\nétats. La <strong>matrice de transition</strong> de <math>(X_n)</math> est la matrice carrée d’ordre <math>m</math> dont le coefficient situé à la <math>i</math>-ième ligne et à la <math>j</math>-ième colonne\nest égal à <math>p_{i,j} = P_{(X_n = x_i)}(X_{n+1} = x_j)</math>.</p>\n</div>\n\n<div class=\"formula\">\n<h4>Graphe associé à une chaîne de Markov</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des\nétats. On associe à cette chaîne de Markov un graphe probabiliste <math>G</math> d’ordre <math>m</math> dont les sommets sont\nles états <math>x_i</math> et dont les arêtes <math>x_i - x_j</math> sont pondérées par les poids <math>p_{i,j} = P_{(X_n = x_i)}(X_{n+1} = x_j)</math>.</p>\n<p>La matrice de transition de <math>(X_n)</math> est égale à la\nmatrice de transition du graphe probabiliste <math>G</math> : il\ns’agit donc aussi d’une matrice stochastique.</p>\n</div>\n\n<h3 id=\"distributions-dans-une-chaine-de-markov\">Distributions dans une chaîne de Markov</h3>\n<div class=\"formula\">\n<h4>Proposition</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des\nétats. On pose <math>p_{i,j}^{(k)} = P_{(X_0 = x_i)}(X_k = x_j)</math> pour tout <math>k \\in \\mathbb{N}^*</math> (qui\nreprésente la probabilité que la chaîne de Markov <math>(X_n)</math> passe de l’état <math>x_i</math> à l’état\n<math>x_j</math> en <math>k</math> étapes). On a : </p><div class=\"katex-display\"><math displaystyle>p_{i,j}^{(k)} = \\sum_{q=1}^m p_{i,q}^{(k-1)} \\times p_{q,j}^{(1)} = p_{i,1}^{(k-1)} \\times p_{1,j}^{(1)} + p_{i,2}^{(k-1)} \\times p_{2,j}^{(1)} + \\dots + p_{i,m}^{(k-1)} \\times p_{m,j}^{(1)}</math></div>\nDe plus, comme <math>(X_n)</math> est homogène, <math>p_{i,j}^{(k)} = p_{i,j}^{(n+k)}</math> pour tout <math>n \\in \\mathbb{N}</math>.\n</div>\n\n<p>Cette formule semble un petit peu compliquée à interpréter. Elle\nsignifie simplement que la probabilité que la chaîne de Markov <math>(X_n)</math> passe de l’état <math>x_i</math> à l’état\n<math>x_j</math> en <math>k</math> étapes est égale à la\nprobabilité qu’elle passe de l’état <math>e_i</math> à <math>e_q</math> en une étape, puis de passer de <math>e_q</math> à <math>e_j</math> en <math>k-1</math>\nétapes. Heureusement, il est possible de la simplifier grandement à\nl’aide des matrices de transition.</p>\n<div class=\"formula\">\n<h4>Lien avec la matrice de transition</h4>\n<p>En reprenant les notations précédentes et en notant <math>M</math> la matrice de transition de <math>(X_n)</math>,\nalors <math>p_{i,j}^{(k)}</math> est le coefficient à la ligne\n<math>i</math> et à la colonne <math>j</math> de la\nmatrice <math>M^k</math>.</p>\n</div>\n<p>Enfin, donnons la définition centrale de cette section.</p>\n<div data-api-v2-content-width=\"big\" class=\"formula\">\n<h4>Définition</h4>\n\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des\nétats. On appelle <strong>suite des distributions</strong> de <math>(X_n)</math> la suite de matrices <math>(\\pi_n)</math>,\ndéfinie pour tout <math>n \\in \\mathbb{N}</math> par <math>\\pi_n = \\begin{pmatrix} P(X_n = x_1) & P(X_n = x_2) & \\dots & P(X_n = e_m) \\end{pmatrix}</math>.</p>\n<p><math>\\pi_n</math> est donc une matrice ligne d’ordre <math>m</math> et est appelée <strong>distribution au temps <math>n</math></strong>.</p>\n<p><math>\\pi_0</math> (la distribution au temps <math>0</math>) est appelée <strong>distribution\ninitiale</strong>.</p>\n</div>\n<p>Une propriété très sympathique des distributions, est que l’on\ndispose d’une relation de récurrence permettant de calculer facilement\nla distribution à un temps <math>n</math> donné.</p>\n<div class=\"formula\">\n<h4>Relation entre <math>\\pi_{n+1}</math> et <math>\\pi_n</math></h4>\n<p>En reprenant les notations de la définition précédente et en notant\n<math>M</math> la matrice de transition de <math>(X_n)</math>, alors la suite <math>(\\pi_n)</math>\nvérifie une relation de récurrence donnée pour tout <math>n \\in \\mathbb{N}</math> par <math>\\pi_{n+1} = \\pi_n M</math>.</p>\n<p>On en déduit que pour tout <math>n \\in \\mathbb{N}</math>, <math>\\pi_n = \\pi_0 M^n</math>.</p>\n</div>\n\n\n<h3 id=\"distribution-invariante\">Distribution invariante</h3>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène de\nmatrice de transition <math>M</math>. Une distribution <math>\\pi</math> est <strong>invariante</strong> si les deux\nconditions suivantes sont respectées :</p>\n<ul>\n<li><p><math>\\pi M = \\pi</math> (donc si <math>\\pi</math>\nest une distribution à un temps <math>n</math>, on a <math>\\pi = \\pi_n</math> et cette condition se résume à avoir <math>\\pi_n = \\pi_n M = \\pi_{n+1}</math>).</p></li>\n<li><p>La somme des coefficients de <math>\\pi</math> vaut <math>1</math>.</p></li>\n</ul>\n</div>\n<div class=\"formula\">\n<h4>Existence et unicité de la distribution invariante au temps <math>n</math></h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène de\nmatrice de transition <math>M</math>.</p>\n<p>Si <math>M</math> ne possède aucun coefficient non nul autre\nque sur sa diagonale, alors <math>(X_n)</math> admet une unique\ndistribution invariante <math>\\pi</math>.</p>\n</div>\n<div class=\"formula\">\n<h4>Convergence de la distribution</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>(\\pi_n)</math> la suite des distributions.</p>\n<ul>\n<li><p>Si <math>(\\pi_n)</math> est une suite de matrices\nconvergente, alors elle converge vers une distribution invariante <math>\\pi</math>.</p></li>\n<li><p>Si le cardinal de l’ensemble des états de <math>(X_n)</math> est <math>2</math>, alors <math>(\\pi_n)</math> est convergente (et converge vers la\ndistribution invariante <math>\\pi</math>).</p></li>\n</ul>\n</div>\n\n"}