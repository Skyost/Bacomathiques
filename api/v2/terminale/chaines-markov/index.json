{"api":{"version":2,"latestVersion":2},"lesson":{"id":"chaines-markov","level":"terminale","title":"Chaînes de Markov","chapter":16,"specialty":true,"content":"/api/v2/terminale/chaines-markov/","comments":"/api/v2/terminale/chaines-markov/comments/","summary":"/api/v2/terminale/chaines-markov/summary/"},"difficulty":5,"pdf":"/pdf/terminale/chaines-markov.pdf","html":"\n\n\n\n\n\n\n\n<h2 id=\"graphe-pondere-et-graphe-probabiliste\">Graphe pondéré et graphe probabiliste</h2>\n<h3 id=\"definition\">Définition</h3>\n<div class=\"formula\">\n<h4>Graphe pondéré</h4>\n<p>Un graphe est dit <strong>pondéré</strong> si chacune de ses arêtes\nest affecté d’un nombre positif (ou nul) que l’on appelle\n<strong>poids</strong>.</p>\n<p>Le poids d’une chaîne (ou d’un chemin) est la somme des poids de ses\narêtes.</p>\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>On considère le graphe orienté et pondéré suivant :</p>\n<div class=\"center\">\n<p><img src=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-1.svg\" alt=\"graphe-1\" data-src-dark=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-1.svg\"></p>\n</div>\n<p>On a :</p>\n<ul>\n<li><p>Le poids de l’arête <math>A-B</math> vaut <math>0</math>.</p></li>\n<li><p>Le poids du chemin <math>A-B-C-A-D</math> vaut <math>0+4+2+7 = 13</math>.</p></li>\n</ul>\n</div>\n<div class=\"formula\">\n<h4>Graphe probabiliste</h4>\n<p>On appelle <strong>graphe probabiliste</strong> un graphe orienté et\npondéré tel que :</p>\n<ul>\n<li><p>Pour chaque sommet, la somme des poids des arcs issus de ce\nsommet vaut <math>1</math>.</p></li>\n<li><p>Il y a au plus <math>1</math> arrête orientée reliant\nchaque sommet.</p></li>\n</ul>\n</div>\n<p>Il peut être utile de faire l’analogie entre les graphes\nprobabilistes et <a href=\"https://bacomathiqu.es/cours/premiere/probabilites/#arbre-de-probabilite\">les\narbres de probabilité</a> vus en classe de Première.</p>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Faisons un exemple concret. On souhaite étudier l’évolution d’une\nmaladie chez un certain individu. À un jour donné, cet individu est soit\nmalade (que l’on note <math>M</math>), soit soigné (que l’on note\n<math>S</math>). On suppose que pour cette maladie :</p>\n<ul>\n<li><p>La probabilité qu’une personne malade guérisse le lendemain est\n<math>0,4</math>.</p></li>\n<li><p>La probabilité qu’une personne saine tombe malade le lendemain\nest <math>0,1</math>.</p></li>\n</ul>\n<p>Le graphe probabiliste modélisant cette situation est le graphe <math>G</math> suivant :</p>\n<div class=\"center\">\n<p><img src=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-2.svg\" alt=\"graphe-2\" data-src-dark=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-2.svg\"></p>\n</div>\n<p>On remarque que la somme des poids des arêtes issues du sommet <math>S</math> vaut <math>0,9+0,1 = 1</math> (idem pour <math>M</math> qui vaut <math>0,6+0,4 = 1</math>).</p>\n</div>\n<h3 id=\"matrice-de-transition\">Matrice de transition</h3>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit <math>G</math> un graphe probabiliste d’ordre <math>n</math>. On appelle <strong>matrice de transition</strong> du\ngraphe <math>G</math>, la matrice carrée d’ordre <math>n</math> dont le coefficient à la ligne <math>i</math>\net à la colonne <math>j</math> est égal au poids de l’arête\nreliant le sommet <math>i</math> au sommet <math>j</math>.</p>\n<p>Une telle matrice est qualifiée de <strong>stochastique</strong> car\nla somme des coefficients de chacune de ses lignes vaut <math>1</math>.</p>\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Dans l’exemple précédent (en supposant que <math>S</math> est\nle 1 sommet et que <math>M</math> est le 2ème) la matrice de\ntransition du graphe <math>G</math> est <math>\\begin{pmatrix} 0,9 & 0,1 \\\\ 0,4 & 0,6 \\end{pmatrix}</math>.</p>\n</div>\n<p>Attention cependant à ne pas confondre matrice de transition et\nmatrice d’adjacence.</p>\n<h2 id=\"chaines-de-markov\">Chaînes de Markov</h2>\n<h3 id=\"definition-1\">Définition</h3>\n<p>Il vous est fortement conseillé de relire (et de maîtriser) le cours\nsur <a href=\"https://bacomathiqu.es/cours/terminale/variables-aleatoires-concentration-grands-nombres/\">les\nvariables aléatoires</a> avant d’aborder cette section. De plus, sachez\nque cette partie est sans doute la plus difficile du programme de\nTerminale. Mais ne vous découragez pas car elle reste parfaitement\naccessible !</p>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit <math>(X_n)</math> une suite de variables aléatoires\ndiscrètes définies sur un même univers <math>\\Omega</math> et à\nvaleurs dans un ensemble <math>E</math>. On dit que <math>(X_n)</math> définit une <strong>chaîne de Markov</strong> sur\n<math>E</math> si pour tout <math>n \\in \\mathbb{N}</math>\net tout <math>x_0, x_1, x_2, \\dots, x_n \\in E</math>, l’événement\n<math>(X_n = x_n)</math> ne dépend que de l’événement antérieur\n<math>(X_{n-1} = x_{n-1})</math> (et pas des précédents) ;\nautrement dit, si <math>P_{(X_{n-1} = x_{n-1}) \\, \\cap \\dots \\cap \\, (X_0 = x_0)}(X_n = x_n) = P_{(X_{n-1} = x_{n-1})}(X_n = x_n)</math>.</p>\n<p>De plus, l’ensemble <math>E</math> est appelé <strong>espace\ndes états</strong> de la chaîne de Markov.</p>\n</div>\n<p>En français, cela signifie que si <math>X_n</math> représente\nl’état d’un système à un temps <math>n</math>, alors l’état\nsuivant <math>X_{n+1}</math> ne dépend que de l’état au temps <math>n</math> et pas des états précédents. De plus, notez bien que\nnous n’avons pas fait d’hypothèse sur le cardinal de <math>E</math> (qui peut donc être de cardinal <math>m \\in \\mathbb{N}</math>).</p>\n<div class=\"nosummary\">\n<p>En classe de Terminale, nous nous limiterons principalement au cas où\n<math>E</math> possède <math>2</math> voire <math>3</math> éléments, mais nous allons quand-même voir très\nbientôt un exemple de chaîne de Markov à <math>12</math>\nétats.</p>\n</div>\n<div class=\"tip\">\n<h4>Variable aléatoire discrète</h4>\n<p>Une variable aléatoire <math>X</math> définie sur un univers\n<math>\\Omega</math> est dite <strong>discrète</strong> si <math>X(\\Omega)</math> est un ensemble dénombrable.</p>\n</div>\n<div class=\"formula\">\n<h4>Chaîne de Markov homogène</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov dont on note <math>E</math> l’espace des états. Alors <math>(X_n)</math>\nest dite <strong>homogène</strong> si pour tout <math>n \\in \\mathbb{N}</math> et pour tout <math>x</math>, <math>y \\in E</math>, la probabilité <math>P_{(X_n = x)}(X_{n+1} = y)</math>\nest indépendante de <math>n</math>.</p>\n<p>En termes mathématiques, cela signifie que pour tout <math>n \\in \\mathbb{N}</math> et pour tout <math>x</math>, <math>y \\in E</math>, <math>P_{(X_n = x)}(X_{n+1} = y) = P_{(X_0 = x)}(X_1 = y)</math>.</p>\n</div>\n<div data-api-v2-content-width=\"big\" class=\"tip\">\n<h4>Exemple</h4>\n\n<p>Eliott fait la collection des vignettes des 11 joueurs titulaires de\nl’Équipe de France de football qu’il trouve dans des paquets de\ncéréales. À chaque fois qu’il achète un paquet, il a donc une\nprobabilité de <math>\\frac{1}{11}</math> de tomber sur le <math>k</math>-ième joueur (pour tout <math>k</math> compris\nentre <math>1</math> et <math>11</math>).</p>\n<p>Si on note par <math>X_n</math> le nombre de vignettes\ndifférentes dans la collection d’Eliott après qu’il eut ouvert <math>n</math> paquets de céréales, alors <math>(X_n)</math>\nest une chaîne de Markov homogène (commençant par <math>X_0 = 0</math>). En effet, pour tout <math>k \\in \\{0, 1, \\dots, 11\\}</math>, on a que l’événement <math>(X_{n+1} = k)</math> ne\ndépend que de <math>X_n</math> :</p>\n<p></p><div class=\"katex-display\"><math displaystyle>P_A(X_{n+1} = k) = \\begin{cases}       \\frac{k}{11} \\text{ si } A \\text{ est l'événement } (X_n = k) \\\\       1 - \\frac{k-1}{11} \\text{ si } A \\text{ est l'événement } (X_n = k-1) \\text{ et que } k \\geq 1 \\\\       0 \\text{ sinon}     \\end{cases}</math></div>\n<p>Pour détailler un peu plus :</p>\n<ul>\n<li><p>Si on a <math>(X_n = k)</math> (i.e. on a déjà tiré <math>k</math> joueurs différents), alors la probabilité d’avoir <math>(X_{n+1} = k)</math> est égale à la probabilité de ne pas tirer\nde nouveau joueur (qui est <math>\\frac{k}{11}</math>). Cela\ninclut également le cas où <math>k = 11</math>.</p></li>\n<li><p>Si on a <math>(X_n = k-1)</math> (i.e. on a déjà tiré <math>k-1</math> joueurs différents), alors la probabilité d’avoir\n<math>(X_{n+1} = k)</math> est égale à la probabilité de tirer un\nnouveau joueur (qui est <math>1 - \\frac{k-1}{11}</math>).</p></li>\n<li><p>Sinon, comme on ne peut pas tirer plus d’un nouveau joueur d’un\ncoup ou en enlever de la collection, la probabilité d’avoir <math>(X_{n+1} = k)</math> est égale à <math>0</math>.</p></li>\n<li><p>Notons de plus que <math>(X_n)</math> est homogène car le\ncalcul de <math>P(X_{n+1} = k)</math> est indépendant de <math>n</math> (mais reste dépendant de <math>X_n</math>,\nattention).</p></li>\n</ul>\n<p>De plus, l’espace des états <math>E</math> est <math>\\{0, 1, \\dots, 11\\}</math>.</p>\n<p>Cet exemple est très connu et porte un nom : il s’agit du\n<strong>problème du collectionneur de vignettes</strong>. Pour votre\nculture, sachez qu’en moyenne, il faudra ouvrir environ <math>n \\ln(n)</math> paquets de céréales pour compléter une collection de <math>n</math> vignettes.</p>\n</div>\n<h3 id=\"matrice-et-graphe-associes-a-une-chaine-de-markov\">Matrice et graphe associés à une chaîne de Markov</h3>\n<div class=\"formula\">\n<h4>Matrice de transition</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des\nétats. La <strong>matrice de transition</strong> de <math>(X_n)</math> est la matrice carrée d’ordre <math>m</math> dont le coefficient situé à la <math>i</math>-ième ligne et à la <math>j</math>-ième colonne\nest égal à <math>p_{i,j} = P_{(X_n = x_i)}(X_{n+1} = x_j)</math>.</p>\n</div>\n<div class=\"tip\">\n\n<p>Comme cette probabilité est indépendante de <math>n</math>, on\npeut tout à fait prendre <math>n = 0</math> dans la définition.\nOn a alors <math>p_{i,j} = P_{(X_0 = x_i)}(X_1 = x_j)</math>.</p>\n</div>\n<div class=\"formula\">\n<h4>Graphe associé à une chaîne de Markov</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des\nétats. On associe à cette chaîne de Markov un graphe probabiliste <math>G</math> d’ordre <math>m</math> dont les sommets sont\nles états <math>x_i</math> et dont les arêtes <math>x_i - x_j</math> sont pondérées par les poids <math>p_{i,j} = P_{(X_n = x_i)}(X_{n+1} = x_j)</math>.</p>\n<p>La matrice de transition de <math>(X_n)</math> est égale à la\nmatrice de transition du graphe probabiliste <math>G</math> : il\ns’agit donc aussi d’une matrice stochastique.</p>\n</div>\n<div data-api-v2-content-width=\"big\" class=\"tip\">\n<h4>Exemple</h4>\n\n<p>Reprenons l’exemple précédent. Alors la matrice de transition\nassociée à <math>(X_n)</math> est la matrice <math>M \\in \\mathcal{M}_{12}(\\mathbb{R})</math> : <span> <div class=\"katex-display\"><math displaystyle>M = \\begin{pmatrix} 0 & 1 & \\dots & 0 & 0 \\\\ 0 & \\frac{1}{11} & \\ddots & 0 & 0 \\\\         \\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\ 0 & 0 & \\ddots & \\frac{10}{11} & \\frac{1}{11} \\\\         0 & 0 & \\dots & 0 & 1 \\\\ \\end{pmatrix}</math></div>\n</span> Et le graphe associé à <math>(X_n)</math> est le graphe\nprobabiliste d’ordre <math>12</math> :</p>\n<div class=\"center\">\n<p><img src=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-3.svg\" alt=\"graphe-3\" data-src-dark=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-3.svg\"></p>\n</div>\n</div>\n<h3 id=\"distributions-dans-une-chaine-de-markov\">Distributions dans une chaîne de Markov</h3>\n<div class=\"formula\">\n<h4>Proposition</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des\nétats. On pose <math>p_{i,j}^{(k)} = P_{(X_0 = x_i)}(X_k = x_j)</math> pour tout <math>k \\in \\mathbb{N}^*</math> (qui\nreprésente la probabilité que la chaîne de Markov <math>(X_n)</math> passe de l’état <math>x_i</math> à l’état\n<math>x_j</math> en <math>k</math> étapes). On a : </p><div class=\"katex-display\"><math displaystyle>p_{i,j}^{(k)} = \\sum_{q=1}^m p_{i,q}^{(k-1)} \\times p_{q,j}^{(1)} = p_{i,1}^{(k-1)} \\times p_{1,j}^{(1)} + p_{i,2}^{(k-1)} \\times p_{2,j}^{(1)} + \\dots + p_{i,m}^{(k-1)} \\times p_{m,j}^{(1)}</math></div>\nDe plus, comme <math>(X_n)</math> est homogène, <math>p_{i,j}^{(k)} = p_{i,j}^{(n+k)}</math> pour tout <math>n \\in \\mathbb{N}</math>.\n</div>\n<div data-api-v2-content-width=\"big\" class=\"proof\">\n<h4>Proposition</h4>\n\n<p></p><div class=\"katex-display\"><math displaystyle>\\begin{aligned}             p_{i,j}^{(k)} &= P_{(X_0 = x_i)}(X_k = x_j) \\\\             &= \\sum_{q=1}^m P_{(X_0 = x_i)}((X_k = x_j) \\, \\cap \\, (X_{k-1} = x_q)) \\\\             &= \\sum_{q=1}^m P_{(X_{k-1} = x_q) \\, \\cap \\, (x_0 = x_i)}(X_k = x_j) P_{(X_0 = x_i)}(X_{k-1} = x_q) \\text{ (probabilités totales)} \\\\             &= \\sum_{q=1}^m P_{(X_{k-1} = x_q)}(X_k = x_j) P_{(X_0 = x_i)}(X_{k-1} = x_q) \\\\             &= \\sum_{q=1}^m P_{(X_0 = x_q)}(X_1 = x_j) P_{(X_0 = x_i)}(X_{k-1} = x_q) \\text{ (homogénéité)} \\\\             &= \\sum_{q=1}^m p_{j,q}^{(1)} \\times p_{i,q}^{(k-1)}          \\end{aligned}</math></div>\n</div>\n<p>Cette formule semble un petit peu compliquée à interpréter. Elle\nsignifie simplement que la probabilité que la chaîne de Markov <math>(X_n)</math> passe de l’état <math>x_i</math> à l’état\n<math>x_j</math> en <math>k</math> étapes est égale à la\nprobabilité qu’elle passe de l’état <math>e_i</math> à <math>e_q</math> en une étape, puis de passer de <math>e_q</math> à <math>e_j</math> en <math>k-1</math>\nétapes. Heureusement, il est possible de la simplifier grandement à\nl’aide des matrices de transition.</p>\n<div class=\"formula\">\n<h4>Lien avec la matrice de transition</h4>\n<p>En reprenant les notations précédentes et en notant <math>M</math> la matrice de transition de <math>(X_n)</math>,\nalors <math>p_{i,j}^{(k)}</math> est le coefficient à la ligne\n<math>i</math> et à la colonne <math>j</math> de la\nmatrice <math>M^k</math>.</p>\n</div>\n<p>Enfin, donnons la définition centrale de cette section.</p>\n<div data-api-v2-content-width=\"big\" class=\"formula\">\n<h4>Définition</h4>\n\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des\nétats. On appelle <strong>suite des distributions</strong> de <math>(X_n)</math> la suite de matrices <math>(\\pi_n)</math>,\ndéfinie pour tout <math>n \\in \\mathbb{N}</math> par <math>\\pi_n = \\begin{pmatrix} P(X_n = x_1) & P(X_n = x_2) & \\dots & P(X_n = e_m) \\end{pmatrix}</math>.</p>\n<p><math>\\pi_n</math> est donc une matrice ligne d’ordre <math>m</math> et est appelée <strong>distribution au temps <math>n</math></strong>.</p>\n<p><math>\\pi_0</math> (la distribution au temps <math>0</math>) est appelée <strong>distribution\ninitiale</strong>.</p>\n</div>\n<p>Une propriété très sympathique des distributions, est que l’on\ndispose d’une relation de récurrence permettant de calculer facilement\nla distribution à un temps <math>n</math> donné.</p>\n<div class=\"formula\">\n<h4>Relation entre <math>\\pi_{n+1}</math> et <math>\\pi_n</math></h4>\n<p>En reprenant les notations de la définition précédente et en notant\n<math>M</math> la matrice de transition de <math>(X_n)</math>, alors la suite <math>(\\pi_n)</math>\nvérifie une relation de récurrence donnée pour tout <math>n \\in \\mathbb{N}</math> par <math>\\pi_{n+1} = \\pi_n M</math>.</p>\n<p>On en déduit que pour tout <math>n \\in \\mathbb{N}</math>, <math>\\pi_n = \\pi_0 M^n</math>.</p>\n</div>\n<div data-api-v2-content-width=\"big\" class=\"proof\">\n<h4>Relation entre <math>\\pi_{n+1}</math> et <math>\\pi_n</math></h4>\n\n<p>Soit <math>n \\in \\mathbb{N}</math>. Les événements <math>(X_n = x_1), (X_n = x_2), \\dots, (X_n =x_m)</math>\npartitionnent (recouvrent) notre univers, donc par la formule des\nprobabilités totales appliquée à notre système complet d’événements et à\n<math>(X_{n+1} = x_j)</math> : </p><div class=\"katex-display\"><math displaystyle>\\begin{aligned}             P(X_{n+1} = x_j) &= P((X_{n+1} = x_j) \\, \\cap \\, (X_n = x_1)) + \\dots + P((X_{n+1} = x_j) \\, \\cap \\, (X_n = x_m)) \\\\             &= P_{(X_n = x_1)}(X_{n+1} = x_j) \\times P(X_n = x_1) + \\dots + P_{(X_n = x_m)}(X_{n+1} = x_j) \\times (X_n = x_m) \\\\             &= \\pi_n M          \\end{aligned}</math></div> Et la formule <math>\\pi_n = \\pi_0 M^n</math>\nse déduit de la formule d’une suite géométrique (où <math>M</math> serait <q>la raison</q> et <math>\\pi_0</math>\nle premier terme).\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Intéressons-nous à l’alimentation d’un chat durant la journée. Il\ndispose de trois gamelles différentes <math>L</math>, <math>C</math> et <math>P</math> dans lesquelles se trouvent\nrespectivement du lait, des croquettes et de la pâté. On suppose que le\nchat a commencé sa journée par du lait et que toutes les heures, il se\ndirige vers une des gamelles suivant le graphe probabiliste ci-dessous\n:</p>\n<div class=\"center\">\n<p><img src=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-4.svg\" alt=\"graphe-4\" data-src-dark=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-4.svg\"></p>\n</div>\n<p>On note par <math>X_n</math> la variable aléatoire qui donne\nla gamelle qu’a choisi le chat à la <math>n</math>-ième heure. On\na donc que <math>(X_n)</math> est une chaîne de Markov homogène\ndont l’espace des états est <math>E = \\{L; C; P\\}</math>. Si on\nnote <math>(\\pi_n)</math> la suite des distributions de <math>(X_n)</math>, on a alors que <math>\\pi_0 = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix}</math>.</p>\n<p>Soit <math>M</math> la matrice de transition <math>M</math> de <math>(X_n)</math>. Calculons quelques\npuissances de <math>M</math> :</p>\n<ul>\n<li><p><math>M = \\begin{pmatrix} 0,5 & 0,3 & 0,2 \\\\ 0,2 & 0,7 & 0,1 \\\\ 0,3 & 0,3 & 0,4 \\end{pmatrix}</math></p></li>\n<li><p><math>M^2 = \\begin{pmatrix} 0,37 & 0,42 & 0,21 \\\\ 0,27 & 0,58 & 0,15 \\\\ 0,33 & 0,42 & 0,25 \\end{pmatrix}</math></p></li>\n<li><p><math>M^3 = \\begin{pmatrix} 0,332 & 0,468 & 0,2 \\\\ 0,296 & 0,532 & 0,172 \\\\ 0,324 & 0,468 & 0,208 \\end{pmatrix}</math></p></li>\n</ul>\n<p>Ainsi :</p>\n<ul>\n<li><p><math>\\pi_1 = \\pi_0 M = \\begin{pmatrix} 0,5 & 0,3 & 0,2 \\end{pmatrix}</math></p></li>\n<li><p><math>\\pi_2 = \\pi_0 M^2 = \\begin{pmatrix} 0,37 & 0,42 & 0,21 \\end{pmatrix}</math></p></li>\n<li><p><math>\\pi_3 = \\pi_0 M^3 = \\begin{pmatrix} 0,332 & 0,468 & 0,2 \\end{pmatrix}</math></p></li>\n</ul>\n<p>Et par exemple <math>p_{1,2}^{(3)} = 0,468</math> : la\nprobabilité que le chat passe à sa gamelle de croquettes 3 heures après\nle lait est d’environ 47 %.</p>\n</div>\n<h3 id=\"distribution-invariante\">Distribution invariante</h3>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène de\nmatrice de transition <math>M</math>. Une distribution <math>\\pi</math> est <strong>invariante</strong> si les deux\nconditions suivantes sont respectées :</p>\n<ul>\n<li><p><math>\\pi M = \\pi</math> (donc si <math>\\pi</math>\nest une distribution à un temps <math>n</math>, on a <math>\\pi = \\pi_n</math> et cette condition se résume à avoir <math>\\pi_n = \\pi_n M = \\pi_{n+1}</math>).</p></li>\n<li><p>La somme des coefficients de <math>\\pi</math> vaut <math>1</math>.</p></li>\n</ul>\n</div>\n<div class=\"formula\">\n<h4>Existence et unicité de la distribution invariante au temps <math>n</math></h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène de\nmatrice de transition <math>M</math>.</p>\n<p>Si <math>M</math> ne possède aucun coefficient non nul autre\nque sur sa diagonale, alors <math>(X_n)</math> admet une unique\ndistribution invariante <math>\\pi</math>.</p>\n</div>\n<div class=\"formula\">\n<h4>Convergence de la distribution</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on\nnote <math>(\\pi_n)</math> la suite des distributions.</p>\n<ul>\n<li><p>Si <math>(\\pi_n)</math> est une suite de matrices\nconvergente, alors elle converge vers une distribution invariante <math>\\pi</math>.</p></li>\n<li><p>Si le cardinal de l’ensemble des états de <math>(X_n)</math> est <math>2</math>, alors <math>(\\pi_n)</math> est convergente (et converge vers la\ndistribution invariante <math>\\pi</math>).</p></li>\n</ul>\n</div>\n<div data-api-v2-content-width=\"big\" class=\"tip\">\n<h4>Exemple</h4>\n\n<p>Reprenons l’exemple précédent et voyons si <math>(X_n)</math>\nadmet une distribution invariante.</p>\n<p>Remarquons tout d’abord que la matrice de transition <math>M</math> ne possède aucun coefficient non nul. Donc <math>(X_n)</math> admet une unique distribution invariante <math>\\pi</math>.</p>\n<p>Posons donc <math>\\pi = \\begin{pmatrix} x & y & z \\end{pmatrix}</math> et déterminons <math>x</math>, <math>y</math> et <math>z</math> :</p>\n<p>On doit avoir <math>\\pi M = \\pi</math>. Cela revient à\nrésoudre le système suivant : </p><div class=\"katex-display\"><math displaystyle>\\begin{pmatrix} x & y & z \\end{pmatrix} \\begin{pmatrix} 0,5 & 0,3 & 0,2 \\\\ 0,2 & 0,7 & 0,1 \\\\ 0,3 & 0,3 & 0,4 \\end{pmatrix} = \\begin{pmatrix} x & y & z \\end{pmatrix} \\tag{S}</math></div> D’où : <div class=\"katex-display\"><math displaystyle>\\begin{aligned}             (S) &\\iff \\begin{pmatrix} 0,5x + 0,2y + 0,3z & 0,3x + 0,7y + 0,3z & 0,2x + 0,1y + 0,4z \\end{pmatrix} = \\begin{pmatrix} x & y & z \\end{pmatrix} \\\\             &\\iff \\begin{cases} \\frac{1}{2}x + \\frac{1}{5}y + \\frac{3}{10}z = x \\\\ \\frac{3}{10}x + \\frac{7}{10}y + \\frac{3}{10}z = y \\\\ \\frac{1}{5}x + \\frac{1}{10}y + \\frac{2}{5}z = z \\end{cases} \\text{ (en passant en écriture fractionnaire)} \\\\             &\\iff \\begin{cases} -\\frac{1}{2}x + \\frac{1}{5}y + \\frac{3}{10}z = 0 \\\\ \\frac{3}{10}x - \\frac{3}{10}y + \\frac{3}{10}z = 0 \\\\ \\frac{1}{5}x + \\frac{1}{10}y - \\frac{3}{5}z = 0 \\end{cases} \\\\             &\\iff \\begin{cases} x = \\frac{2}{5}y + \\frac{3}{5}z \\\\ -\\frac{9}{50}y + \\frac{12}{25}z = 0 \\\\ \\frac{9}{50}y - \\frac{12}{25}z = 0 \\end{cases} \\\\             &\\iff \\begin{cases} x = \\frac{2}{5} \\times \\frac{8}{3} z + \\frac{3}{5}z = \\frac{5}{3}z \\\\ y = \\frac{50}{9} \\times \\frac{12}{25}z = \\frac{8}{3}z \\end{cases}          \\end{aligned}</math></div> Donc <math>\\pi</math> est de la forme <math>\\pi = \\begin{pmatrix} \\frac{5}{3}z & \\frac{8}{3}z & z \\end{pmatrix}</math>. De plus, la somme des coefficients de <math>\\pi</math> doit faire <math>1</math>, donc : <div class=\"katex-display\"><math displaystyle>\\frac{5}{3}z + \\frac{8}{3}z + z = 1 \\iff \\frac{16}{3}z = 1 \\iff z = \\frac{3}{16}</math></div> Donc l’unique distribution invariante <math>\\pi</math> de <math>(X_n)</math> est : <div class=\"katex-display\"><math displaystyle>\\pi = \\begin{pmatrix} \\frac{5}{16} & \\frac{1}{2} & \\frac{3}{16} \\end{pmatrix} = \\begin{pmatrix} 0,3125 & 0,5 & 0,1875 \\end{pmatrix}</math></div>\n</div>\n"}