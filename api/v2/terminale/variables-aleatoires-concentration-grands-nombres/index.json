{"api":{"version":2,"latestVersion":2},"lesson":{"id":"variables-aleatoires-concentration-grands-nombres","level":"terminale","title":"Variables aléatoires, concentration et loi des grands nombres","chapter":11,"specialty":false,"content":"/api/v2/terminale/variables-aleatoires-concentration-grands-nombres/","comments":"/api/v2/terminale/variables-aleatoires-concentration-grands-nombres/comments/","summary":"/api/v2/terminale/variables-aleatoires-concentration-grands-nombres/summary/"},"difficulty":5,"pdf":"/pdf/terminale/variables-aleatoires-concentration-grands-nombres.pdf","html":"\n\n\n\n\n\n\n\n<h2 id=\"somme-de-deux-variables-aleatoires\">Somme de deux variables aléatoires</h2>\n<h3 id=\"definition\">Définition</h3>\n<p>Il arrive que, on ne puisse pas modéliser une situation donnée à\nl’aide d’une seule variable aléatoire <q>simple</q>. C’est pourquoi il\nest parfois utile d’en additionner plusieurs ou bien d’en multiplier par\nun réel.</p>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soient <math>X</math> et <math>Y</math> deux variables\naléatoires définies sur un univers <math>\\Omega</math> et soit\n<math>\\lambda</math> un réel. On définit :</p>\n<ul>\n<li><p><math>X + Y</math> la variable aléatoire somme de <math>X</math> et <math>Y</math> définie pour tout <math>\\omega \\in \\Omega</math> par <math>(X + Y)(\\omega) = X(\\omega) + Y(\\omega)</math>.</p></li>\n<li><p><math>\\lambda X</math> la variable aléatoire produit de\n<math>\\lambda</math> et <math>X</math> définie pour tout\n<math>\\omega \\in \\Omega</math> par <math>(\\lambda X)(\\omega) = \\lambda X(\\omega)</math>.</p></li>\n</ul>\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Encore une fois, il s’agit d’une définition un peu compliquée.\nIllustrons ceci par un exemple.</p>\n<p>On lance deux dés différents, équilibrés, et numérotés de <math>1</math> à <math>6</math>. On note par <math>X</math> la variable aléatoire donnant le résultat sur lequel\ntombe le premier dé, et par <math>Y</math> la variable aléatoire\ndonnant le résultat sur lequel tombe le second dé.</p>\n<p>Dans cette situation, la variable aléatoire somme <math>X + Y</math> donne la somme obtenue en additionnant le nombre sur lequel le\npremier dé est tombé avec celui sur lequel le deuxième dé est tombé.</p>\n</div>\n<h3 id=\"esperance-variance-et-ecart-type\">Espérance, variance et écart-type</h3>\n<p>Une somme de variable aléatoire reste une variable aléatoire. Donc il\nest tout à fait possible de calculer l’espérance, la variance,\nl’écart-type, ... d’une somme de variables aléatoires.</p>\n<p>Voyons dans un premier temps une propriété de l’espérance permettant\nde calculer plus facilement l’espérance d’une combinaison linéaire de\nvariables aléatoires.</p>\n<div class=\"formula\">\n<h4>Linéarité de l’espérance</h4>\n<p>Soient <math>X</math> et <math>Y</math> deux variables\naléatoires définies sur un univers <math>\\Omega</math> et soit\n<math>\\lambda</math> un réel. Alors :</p>\n<ul>\n<li><p><math>E(X + Y) = E(X) + E(Y)</math>.</p></li>\n<li><p><math>E(\\lambda X) = \\lambda E(X)</math>.</p></li>\n</ul>\n</div>\n<div class=\"tip\">\n<h4>Applications</h4>\n<p>Appliquons la première formule à l’exemple de la partie\nprécédente.</p>\n<p>On a <math>E(X) = E(Y) = 1 \\times \\frac{1}{6} + 2 \\times \\frac{1}{6} + 3 \\times \\frac{1}{6} + 4 \\times \\frac{1}{6} + 5 \\times \\frac{1}{6} + 6 \\times \\frac{1}{6} = 3,5</math>.</p>\n<p>Donc <math>E(X+Y) = E(X) + E(Y) = 3,5 + 3,5 = 7</math>.</p>\n<p>L’interprétation de ces calculs est, qu’en moyenne, sur un grand\nnombre de lancers, la somme obtenue lorsque l’on additionne le résultat\ndes deux dés vaut <math>7</math>.</p>\n</div>\n<p>Voyons désormais des formules permettant de calculer la variance et\nl’écart-type d’une combinaison linéaire de variables aléatoires.</p>\n<div class=\"formula\">\n<h4>Variance et écart-type</h4>\n<p>Soient <math>X</math> et <math>Y</math> deux variables\naléatoires définies sur un univers <math>\\Omega</math> et soit\n<math>\\lambda</math> un réel. Alors :</p>\n<ul>\n<li><p><math>V(X + Y) = V(X) + V(Y)</math> si <math>X</math> et <math>Y</math> sont indépendantes\n(c’est-à-dire si le résultat de l’une n’a pas d’incidence sur le\nrésultat de l’autre).</p></li>\n<li><p><math>V(\\lambda X) = \\lambda^2 V(X)</math>.</p></li>\n<li><p><math>\\sigma(\\lambda X) = \\sqrt{\\lambda^2} \\sigma(X)</math>.</p></li>\n</ul>\n</div>\n<h2 id=\"somme-de-plusieurs-variables-aleatoires\">Somme de plusieurs variables aléatoires</h2>\n<h3 id=\"definition-et-proprietes\">Définition et propriétés</h3>\n<p>Nous allons tenter de généraliser un petit peu le concept vu dans la\nsection précédente. En effet, au lieu d’étudier la somme de deux\nvariables aléatoires, on va étudier la somme de <math>n</math>\nvariables aléatoires.</p>\n<p>En classe de Terminale, on se limite au cas où ces variables\naléatoires suivent une même loi.</p>\n<div class=\"formula\">\n<h4>Échantillon aléatoire</h4>\n<p>Un <math>n</math>-uplet de variables aléatoires <math>(X_1, X_2, \\dots, X_n)</math> qui sont toutes indépendantes et\nqui suivent une même loi de probabilité est appelé <strong>échantillon\naléatoire de taille <math>n</math> associé à cette\nloi</strong>.</p>\n</div>\n<div class=\"formula\">\n<h4>Espérance de variables aléatoires de même loi</h4>\n<p>Soit <math>(X_1, X_2, \\dots, X_n)</math> un échantillon\naléatoire de taille <math>n</math>. On pose <math>S_n = X_1 + X_2 + \\dots + X_n</math> et <math>M_n = \\frac{S_n}{n}</math>.\nAlors :</p>\n<ul>\n<li><p><math>E(S_n) = nE(X_1)</math> et <math>V(S_n) = nV(X_1)</math>.</p></li>\n<li><p><math>E(M_n) = E\\left(\\frac{S_n}{n}\\right) = \\frac{E(S_n)}{n} = E(X_1)</math> et <math>V(M_n) = \\frac{V(S_n)}{n^2} = \\frac{V(X_1)}{n}</math>.</p></li>\n</ul>\n</div>\n<div class=\"tip\">\n<h4>Note</h4>\n<p>Petite note sur le nom des variables aléatoires précédentes :</p>\n<ul>\n<li><p><math>S_n</math> est la <strong>somme</strong> des <math>n</math> variables aléatoires.</p></li>\n<li><p><math>M_n</math> est la <strong>moyenne empirique</strong>\ndes <math>n</math> variables aléatoires.</p></li>\n</ul>\n</div>\n<h3 id=\"somme--decompositions-de-certaines-variables-aleatoires\">Somme / décompositions de certaines variables aléatoires</h3>\n<p>Nous allons maintenant énoncer une propriété utile qui permet de\ntrouver la loi suivie par une somme de variables aléatoires\nindépendantes suivant une loi de Bernoulli.</p>\n<div class=\"formula\">\n<h4>Somme de variables aléatoires indépendantes suivant une même loi de\nBernoulli</h4>\n<p>Soit <math>(X_1, X_2, \\dots, X_n)</math> un échantillon\naléatoire de taille <math>n</math> associé à une loi de Bernoulli\nde paramètre <math>p</math>.</p>\n<p>Alors <math>X_1 + X_2 + \\dots + X_n</math> suit une loi\nbinomiale <math>\\mathcal{B}(n; p)</math>.</p>\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>On lance en même temps deux pièces équilibrées en l’air. On suppose\nqu’un succès est représenté par Pile.</p>\n<p>On modélise le résultat de la première par une variable aléatoire <math>X</math> qui suit une loi de Bernoulli <math>\\mathcal{B}(0,5)</math>. De même, on modélise le résultat de la\nseconde par une variable aléatoire <math>Y</math> suivant la même\nloi que <math>X</math>.</p>\n<p>Alors <math>X + Y</math> (qui modélise le nombre de Pile\nobtenus au total par les deux pièces) suit une loi binomiale <math>\\mathcal{B}(2; 0,5)</math>.</p>\n</div>\n<p>Enfin, signalons qu’il existe une réciproque de la première propriété\nqui permet de <q>transformer</q> une variable aléatoire suivant une loi\nbinomiale en somme de variables aléatoires suivant une loi de\nBernoulli.</p>\n<div class=\"formula\">\n<h4>Décomposition d’une variable aléatoire suivant une loi\nbinomiale</h4>\n<p>Soit <math>X</math> une variable aléatoire suivant une loi\nbinomiale <math>\\mathcal{B}(n; p)</math>.</p>\n<p>Alors il existe <math>n</math> variables aléatoires\nindépendantes <math>X_1</math>, <math>X_2</math>, ... ,\n<math>X_n</math> suivant toutes une loi de Bernoulli <math>\\mathcal{B}(p)</math>, et telles que <math>X = X_1 + X_2 + \\dots + X_n</math>.</p>\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Soit <math>X</math> suivant une loi binomiale <math>\\mathcal{B}\\left(3; \\frac{1}{6}\\right)</math>. Alors par la\npropriété précédente, il existe <math>X_1</math>, <math>X_2</math> et <math>X_3</math>, indépendantes et suivant\nune loi <math>\\mathcal{B}\\left(\\frac{1}{6}\\right)</math> telles\nque <math>X = X_1 + X_2 + X_3</math>.</p>\n</div>\n<h2 id=\"concentration-et-loi-des-grands-nombres\">Concentration et loi des grands nombres</h2>\n<h3 id=\"inegalite-de-bienayme-tchebychev\">Inégalité de Bienaymé-Tchebychev</h3>\n<div class=\"formula\">\n<h4>Inégalité de Bienaymé-Tchebychev</h4>\n<p>Soit <math>X</math> une variable aléatoire d’espérance <math>E(X) = \\mu</math> et de variance <math>V(X) = V</math>.\nAlors pour tout réel strictement positif <math>\\delta</math>, <math>P(|X-\\mu| \\geq \\delta) \\leq \\frac{V}{\\delta^2}</math>.</p>\n</div>\n<div class=\"tip\">\n<h4>Autre formulation</h4>\n<p>Une autre formulation de cette inégalité est la suivante : <math>P(X \\notin ]\\mu - \\delta; \\mu + \\delta[) \\leq \\frac{V(X)}{\\delta^2}</math>.</p>\n</div>\n<div class=\"nosummary\">\n<p>Cette inégalité est un peu abstraite, donnons tout de suite un\nexemple.</p>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Le poids moyen d’un bébé en kilogrammes à la naissance peut être\nmodélisé par une variable aléatoire <math>X</math> d’espérance\n<math>\\mu = 3,3</math> et de variance <math>V = 0,25</math>.</p>\n<p>Un bébé est considéré <q>de poids normal</q> si son poids est compris\nentre <math>2,4</math> et <math>4,2</math> kilogrammes.\nNous allons calculer une majoration pour la probabilité qu’un bébé ne\nsoit pas de poids normal à la naissance (c’est-à-dire, si <math>X \\notin ]3,3 - 0,9; 3,3 + 0,9[</math> ou encore si <math>|X - 3,3| \\geq 0,9</math>).</p>\n<p>On a <math>P(|X - 3,3| \\geq 0,9) \\leq \\frac{0,25}{0,9^2} = 0,2025</math> par l’inégalité de Bienaymé-Tchebychev.</p>\n<p>La probabilité qu’un bébé ne soit pas de poids normal à la naissance\nne dépasse pas <math>0,2025</math>.</p>\n<p>C’est majoration n’est pas très satisfaisante, mais elle vient\nprincipalement du fait que la variance est trop élevée.</p>\n</div>\n</div>\n<h3 id=\"inegalite-de-concentration\">Inégalité de concentration</h3>\n<div class=\"formula\">\n<h4>Inégalité de concentration</h4>\n<p>Soit <math>(X_1, X_2, \\dots, X_n)</math> un échantillon\naléatoire de taille <math>n</math> associé à une loi d’espérance\n<math>\\mu</math> et de variance <math>V</math>. On pose\n<math>M_n = \\frac{X_1 + X_2 + \\dots + X_n}{n}</math>, la moyenne\nempirique de cet échantillon.</p>\n<p>Alors pour tout réel strictement positif <math>\\delta</math>,\n<math>P(|M_n - \\mu| \\geq \\delta) \\leq \\frac{V}{n \\delta^2}</math>.</p>\n</div>\n<h3 id=\"loi-des-grands-nombres\">Loi des grands nombres</h3>\n<div class=\"formula\">\n<h4>Loi faible des grands nombres</h4>\n<p>Soit <math>(X_1, X_2, \\dots, X_n)</math> un échantillon\naléatoire de taille <math>n</math> associé à une loi d’espérance\n<math>\\mu</math> et de variance <math>V</math>. On pose\n<math>M_n = \\frac{X_1 + X_2 + \\dots + X_n}{n}</math>, la moyenne\nempirique de cet échantillon.</p>\n<p>Alors pour tout réel strictement positif <math>\\delta</math>,\n<math>\\lim\\limits_{n \\rightarrow +\\infty} P(|M_n - \\mu| \\geq \\delta) = 0</math>.</p>\n</div>\n<div class=\"tip\">\n\n<p>Ce théorème signifie que la moyenne de l’échantillon se rapproche des\nmoyennes des variables aléatoires quand la taille de l’échantillon\naugmente.</p>\n<p>Prenons l’exemple d’une maternité au 1 janvier et supposons que le\npremier-né soit un garçon. Il est tout à fait possible que le deuxième\nbébé soit également un garçon, alors que, statistiquement, on aurait pu\ns’attendre à une fille.</p>\n<p>Mais l’année peut très bien commencer par une dizaine de naissances\nde garçons à la suite !</p>\n<p>Cependant, si on fait un nouveau point au <math>31</math>\ndécembre, on va se rendre compte, qu’effectivement, il y a eu environ 50\n% de naissances de garçons et 50 % de naissances de filles. Il s’agit là\nd’un cas d’application de la loi des grands nombres.</p>\n</div>\n"}